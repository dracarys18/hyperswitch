version: "3.7"

volumes:
  cargo_cache:
  pg_data:
  cargo_build_cache:
  p_cargo_build_cache:
  c_cargo_build_cache:
  redisinsight_store:


networks:
  router_net:


services:
  promtail:
    image: grafana/promtail:latest
    volumes:
      - ./logs:/var/log/router
      - ./config:/etc/promtail
      - /var/run/docker.sock:/var/run/docker.sock
    command: -config.file=/etc/promtail/promtail.yaml
    profiles:
      - monitoring
    networks:
      - router_net

  loki:
    image: grafana/loki:latest
    ports:
      - "3100"
    command: -config.file=/etc/loki/loki.yaml
    networks:
      - router_net
    profiles:
      - monitoring
    volumes:
      - ./config:/etc/loki

  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    command: --config=/etc/otel-collector.yaml
    networks:
      - router_net
    profiles:
      - monitoring
    volumes:
      - ./config/otel-collector.yaml:/etc/otel-collector.yaml
    ports:
      - "4317"
      - "8888"
      - "8889"

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    networks:
      - router_net
    profiles:
      - monitoring
    restart: unless-stopped
    environment:
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_BASIC_ENABLED=false
    volumes:
      - ./config/grafana.ini:/etc/grafana/grafana.ini
      - ./config/grafana-datasource.yaml:/etc/grafana/provisioning/datasources/datasource.yml

  pg:
    image: postgres:14.5
    ports:
      - "5432"
    networks:
      - router_net
    volumes:
      - pg_data:/VAR/LIB/POSTGRESQL/DATA
    cpuset: "10-15"
    environment:
      - POSTGRES_USER=db_user
      - POSTGRES_PASSWORD=db_pass
      - POSTGRES_DB=hyperswitch_db

  jaeger:
    image: jaegertracing/all-in-one:1.43.0
    networks:
      - router_net
    ports:
      - "16686:16686"
      - "14268:14268"
      - "9411:9411"
      - "5778:5778"
      - "6831:6831/udp"
      - "6832:6832/udp"
      - "5775:5775/udp"

  migration_runner:
    image: rust:1.70
    command: "bash -c 'cargo install diesel_cli --no-default-features --features \"postgres\" && diesel migration --database-url postgres://db_user:db_pass@pg:5432/hyperswitch_db run'"
    working_dir: /app
    networks:
      - router_net
    volumes:
      - ./:/app

  hyperswitch-server:
    build:
      context: .
      dockerfile: DockerfileHyperswitch
    ports:
      - "8080:8080"
    networks:
      - router_net
    volumes:
      - ./:/mnt/reports
    cpuset: "3"
    environment:
        - JAEGER_ENDPOINT=jaeger:6831
    labels:
      logs: "promtail"
    healthcheck:
      test: curl --fail http://localhost:8080/health || exit 1
      interval: 100s
      retries: 3
      start_period: 20s
      timeout: 10s

  hyperswitch-producer:
    image: rust:1.70
    command: cargo r --release --bin scheduler -- -f ./config/docker_compose.toml
    working_dir: /app
    networks:
      - router_net
    profiles:
      - scheduler
    volumes:
      - ./:/app
      - cargo_cache:/cargo_cache
      - p_cargo_build_cache:/cargo_build_cache
      - ./target:/mnt/target
    environment:
      - CARGO_TARGET_DIR=/mnt/target
      - SCHEDULER_FLOW=producer
    depends_on:
      hyperswitch-consumer:
        condition: service_healthy
    labels:
      logs: "promtail"

  hyperswitch-consumer:
    image: rust:1.70
    command: cargo r --release --bin scheduler -- -f ./config/docker_compose.toml
    working_dir: /app
    networks:
      - router_net
    profiles:
      - scheduler
    volumes:
      - ./:/app
      - cargo_cache:/cargo_cache
      - c_cargo_build_cache:/cargo_build_cache
      - ./target:/mnt/target
    environment:
      - CARGO_TARGET_DIR=/mnt/target
      - SCHEDULER_FLOW=consumer
    depends_on:
      hyperswitch-server:
        condition: service_started

    labels:
      logs: "promtail"

    healthcheck:
      test: (ps -e | grep scheduler) || exit 1
      interval: 120s
      retries: 3
      start_period: 30s
      timeout: 10s

  redis-cluster:
    image: redis:7
    deploy:
      replicas: ${REDIS_CLUSTER_COUNT:-3}
    command: redis-server /usr/local/etc/redis/redis.conf
    volumes:
      - ./config/redis.conf:/usr/local/etc/redis/redis.conf
    labels:
      - redis
    networks:
      - router_net
    ports:
      - "6379"
      - "16379"

  redis-standalone:
    image: redis:7
    labels:
      - redis
    networks:
      - router_net
    ports:
      - "6379"

  redis-init:
    image: redis:7
    depends_on:
      - redis-cluster
    networks:
      - router_net
    command: "bash -c 'export COUNT=${REDIS_CLUSTER_COUNT:-3}

      \ if [ $$COUNT -lt 3 ]

      \ then

      \ echo \"Minimum 3 nodes are needed for redis cluster\"

      \ exit 1

      \ fi

      \ HOSTS=\"\"

      \ for ((c=1; c<=$$COUNT;c++))

      \ do

      \ NODE=$COMPOSE_PROJECT_NAME-redis-cluster-$$c:6379

      \ echo $$NODE

      \ HOSTS=\"$$HOSTS $$NODE\"

      \ done

      \ echo Creating a cluster with $$HOSTS

      \ redis-cli --cluster create $$HOSTS --cluster-yes

      \ '"

  redis-insight:
    image: redislabs/redisinsight:latest
    networks:
      - router_net
    profiles:
      - full_kv
    ports:
      - "8001:8001"
    volumes:
      - redisinsight_store:/db
  prometheus:
    image: prom/prometheus:latest
    networks:
      - router_net
    profiles:
      - monitoring
    volumes:
      - ./config/prometheus.yaml:/etc/prometheus/prometheus.yml
    ports:
      - "9090"
    restart: unless-stopped

  locust-master:
    image: locustio/locust
    ports:
     - "8089:8089"
    depends_on:
      hyperswitch-server:
        condition: service_healthy
    volumes:
      - ./:/mnt/locust
    command: -f /mnt/locust/locust_home.py --master -H http://locust-master:8089
    environment:
      - JTL_API_TOKEN=at-ed78f00c-a43d-48b8-bf2a-b616e53be118

  locust-worker:
    image: locustio/locust
    volumes:
      - ./:/mnt/locust
    command: -f /mnt/locust/locust_home.py --worker --master-host locust-master
    environment:
      - JTL_API_TOKEN=at-ed78f00c-a43d-48b8-bf2a-b616e53be118
    depends_on:
      - locust-master

  locust-exporter:
    image: containersol/locust_exporter
    ports:
        - "9646:9646"
    environment:
        - LOCUST_EXPORTER_URI=http://locust-master:8089
    depends_on:
        - locust-master

  tempo:
    image: grafana/tempo:latest
    command: -config.file=/etc/tempo.yaml
    volumes:
      - ./config/tempo.yaml:/etc/tempo.yaml
    networks:
      - router_net
    profiles:
      - monitoring
    ports:
      - "3200" # tempo
      - "4317" # otlp grpc
    restart: unless-stopped
  hyperswitch-drainer:
    image: rust:1.70
    command: cargo r --bin drainer --release -- -f ./config/docker_compose.toml
    working_dir: /app
    deploy:
      replicas: ${DRAINER_INSTANCE_COUNT:-1}
    networks:
      - router_net
    profiles:
      - full_kv
    volumes:
      - ./:/app
      - cargo_cache:/cargo_cache
      - ./target:/mnt/target
    environment:
      - CARGO_TARGET_DIR=/mnt/target
    restart: unless-stopped
    depends_on:
      hyperswitch-server:
        condition: service_started
    labels:
      logs: "promtail"
